{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore\n",
    "\n",
    "Noted, Coded, and Created by Han Summer 2024. Part of The 20th Summer Project\n",
    "\n",
    "------------\n",
    "### Makemore\n",
    "\n",
    "Making more things from the data given to the model.\n",
    "\n",
    "Under the hood, **makemore is character level language model**, it means treating every single line example of data from the training set as a sequence of individual characters.\n",
    "\n",
    "Character level language model, simpelnya cuman prediksi huruf yang selanjutnya berdasarkan sequence huruf yang udah ada (before it)\n",
    "\n",
    "----\n",
    "## This page is a the finished implementation of makemore model including Statistic Bigram, NN Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset (List of names) as a python list of strings which is words in this case\n",
    "word= open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=torch.zeros((27,27),dtype=torch.int32)\n",
    "\n",
    "#Make lookup table for character to index\n",
    "chars=sorted(list(set(''.join(word)))) #Concat all the word in the dataset to 1 string, make it set which not allowing duplicate and sorted from a to z\n",
    "#the index will start from 1 since index 0 will be used for start/end token\n",
    "stoi={s:i+1 for i,s in enumerate(chars)} #Make dictionary of character to index {'a': 1, 'b': 2, 'c': 3, 'd': 4, and so on}\n",
    "#Add start token and end token to the dictionary as a '.' and located in index 0\n",
    "stoi['.']=0\n",
    "#Inverse the matrix\n",
    "itos={v:k for k,v in stoi.items()} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bigram(word,namecount):\n",
    "\n",
    "    for w in word:\n",
    "        #Add start token and end token\n",
    "        chs=['.']+list(w)+['.']\n",
    "        for ch1, ch2 in zip(chs, chs[1:]): #Iterate with 2 characters at a time\n",
    "            #Zip bakal stop ketika salah satu elemen habis, seperti chs[1:] habis duluan dibanding w\n",
    "            ix1=stoi[ch1]\n",
    "            ix2=stoi[ch2]\n",
    "            #Counting up the occurence of the bigram\n",
    "            N[ix1, ix2]+=1\n",
    "    # g = torch.Generator().manual_seed(2147483647)\n",
    "    \n",
    "    \n",
    "    P=(N+1).float() #Smoothing the model\n",
    "    P=P/P.sum(1, keepdim=True)\n",
    "    #for loop for how many names will be generated\n",
    "    for i in range (namecount):\n",
    "        out=[]\n",
    "        ix=0\n",
    "        while True:\n",
    "            p=P[ix]\n",
    "            #Generate the sample based on the probability in the row\n",
    "            ix=torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "            out.append(itos[ix])\n",
    "            if ix==0: #This is when the char is '.' aka the end\n",
    "                break\n",
    "        print(''.join(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amciasanelarenthahin.\n",
      "lirarinze.\n",
      "fabe.\n",
      "aimahinn.\n",
      "bionielana.\n",
      "n.\n",
      "a.\n",
      "malartalyon.\n",
      "ziton.\n",
      "mphelyadorudoarueilahkieestondriantolaliye.\n"
     ]
    }
   ],
   "source": [
    "Bigram(word,10) #Generate 10 names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNBigram(epoch,learning_rate):\n",
    "    \n",
    "    #Create the training set of bigrams(x) and the target set of bigrams(y)\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for w in word: #Iterate through all the bigrams\n",
    "        #Add start token and end token\n",
    "        chs=['.']+list(w)+['.']\n",
    "        for ch1, ch2 in zip(chs, chs[1:]): #Iterate with 2 characters at a time\n",
    "            #Zip bakal stop ketika salah satu elemen habis, seperti chs[1:] habis duluan dibanding w\n",
    "            ix1=stoi[ch1]\n",
    "            ix2=stoi[ch2]\n",
    "            #Store the index value to the list\n",
    "            xs.append(ix1)\n",
    "            ys.append(ix2)\n",
    "            \n",
    "    #Convert to tensor (better to use lowercase \"tensor\" not \"Tensor\" since Tensor automatically assign the dtype to float32)\n",
    "    xs=torch.tensor(xs)\n",
    "    ys=torch.tensor(ys)    \n",
    "    num = xs.nelement() #Number of element in the tensor\n",
    "    \n",
    "    # randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "    # g = torch.Generator().manual_seed(2147483647)\n",
    "    W = torch.randn((27, 27), requires_grad=True) #requires_grad=True to make the weight can be updated by the optimizer\n",
    "    \n",
    "    #Model Training, gradient descent\n",
    "    for i in range(epoch):\n",
    "        #Forward pass\n",
    "        xenc = F.one_hot(xs, num_classes=27).float() \n",
    "        logits = xenc @ W \n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdims=True)\n",
    "        loss=-probs[torch.arange(num), ys].log().mean()\n",
    "        \n",
    "        #Backward pass\n",
    "        W.grad=None #Reset the gradient to zero\n",
    "        loss.backward() #Calculate the gradient, torch is like micrograd, it tracks the computation graph\n",
    "        \n",
    "        #Update weight\n",
    "        W.data += -learning_rate * W.grad\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch {i}, Loss {loss.item()}')\n",
    "            \n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 3.800018787384033\n",
      "Epoch 10, Loss 2.659454107284546\n",
      "Epoch 20, Loss 2.5612409114837646\n",
      "Epoch 30, Loss 2.5260512828826904\n",
      "Epoch 40, Loss 2.5074403285980225\n",
      "Epoch 50, Loss 2.4960408210754395\n",
      "Epoch 60, Loss 2.4883546829223633\n",
      "Epoch 70, Loss 2.482818841934204\n",
      "Epoch 80, Loss 2.4786510467529297\n",
      "Epoch 90, Loss 2.4754178524017334\n"
     ]
    }
   ],
   "source": [
    "#Model training\n",
    "W=NNBigram(100,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the neural net do the character prediction\n",
    "def predict_next_char(W):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "    for i in range(5):\n",
    "        out = []\n",
    "        ix = 0\n",
    "        while True:\n",
    "            xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "            logits = xenc @ W # predict log-counts\n",
    "            counts = logits.exp() # counts, equivalent to N\n",
    "            p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "            # ----------\n",
    "            \n",
    "            ix = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "            out.append(itos[ix])\n",
    "            if ix == 0:\n",
    "                break\n",
    "        print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.\n",
      "ly.\n",
      "washja.\n",
      "jan.\n",
      "tlilytlo.\n"
     ]
    }
   ],
   "source": [
    "predict_next_char(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore\n",
    "\n",
    "Noted, Coded, and Created by Han Summer 2024. Part of The 20th Summer Project\n",
    "\n",
    "------------\n",
    "### Makemore\n",
    "\n",
    "Making more things from the data given to the model.\n",
    "\n",
    "Under the hood, **makemore is character level language model**, it means treating every single line example of data from the training set as a sequence of individual characters.\n",
    "\n",
    "Character level language model, simpelnya cuman prediksi huruf yang selanjutnya berdasarkan sequence huruf yang udah ada (before it)\n",
    "\n",
    "----\n",
    "## This page is a the finished implementation of makemore model including Statistic Bigram, NN Bigram with Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset (Run This first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset (List of names) as a python list of strings which is words in this case\n",
    "# Can be changed to any text file with words separated by newlines\n",
    "word= open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=torch.zeros((27,27),dtype=torch.int32)\n",
    "\n",
    "#Make lookup table for character to index\n",
    "chars=sorted(list(set(''.join(word)))) #Concat all the word in the dataset to 1 string, make it set which not allowing duplicate and sorted from a to z\n",
    "#the index will start from 1 since index 0 will be used for start/end token\n",
    "stoi={s:i+1 for i,s in enumerate(chars)} #Make dictionary of character to index {'a': 1, 'b': 2, 'c': 3, 'd': 4, and so on}\n",
    "#Add start token and end token to the dictionary as a '.' and located in index 0\n",
    "stoi['.']=0\n",
    "#Inverse the matrix\n",
    "itos={v:k for k,v in stoi.items()} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bigram(word,namecount):\n",
    "\n",
    "    for w in word:\n",
    "        #Add start token and end token\n",
    "        chs=['.']+list(w)+['.']\n",
    "        for ch1, ch2 in zip(chs, chs[1:]): #Iterate with 2 characters at a time\n",
    "            #Zip bakal stop ketika salah satu elemen habis, seperti chs[1:] habis duluan dibanding w\n",
    "            ix1=stoi[ch1]\n",
    "            ix2=stoi[ch2]\n",
    "            #Counting up the occurence of the bigram\n",
    "            N[ix1, ix2]+=1\n",
    "    # g = torch.Generator().manual_seed(2147483647)\n",
    "    \n",
    "    \n",
    "    P=(N+1).float() #Smoothing the model\n",
    "    P=P/P.sum(1, keepdim=True)\n",
    "    #for loop for how many names will be generated\n",
    "    for i in range (namecount):\n",
    "        out=[]\n",
    "        ix=0\n",
    "        while True:\n",
    "            p=P[ix]\n",
    "            #Generate the sample based on the probability in the row\n",
    "            ix=torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "            out.append(itos[ix])\n",
    "            if ix==0: #This is when the char is '.' aka the end\n",
    "                break\n",
    "        print(''.join(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amciasanelarenthahin.\n",
      "lirarinze.\n",
      "fabe.\n",
      "aimahinn.\n",
      "bionielana.\n",
      "n.\n",
      "a.\n",
      "malartalyon.\n",
      "ziton.\n",
      "mphelyadorudoarueilahkieestondriantolaliye.\n"
     ]
    }
   ],
   "source": [
    "Bigram(word,10) #Generate 10 names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNBigram(epoch,learning_rate):\n",
    "    \n",
    "    #Create the training set of bigrams(x) and the target set of bigrams(y)\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for w in word: #Iterate through all the bigrams\n",
    "        #Add start token and end token\n",
    "        chs=['.']+list(w)+['.']\n",
    "        for ch1, ch2 in zip(chs, chs[1:]): #Iterate with 2 characters at a time\n",
    "            #Zip bakal stop ketika salah satu elemen habis, seperti chs[1:] habis duluan dibanding w\n",
    "            ix1=stoi[ch1]\n",
    "            ix2=stoi[ch2]\n",
    "            #Store the index value to the list\n",
    "            xs.append(ix1)\n",
    "            ys.append(ix2)\n",
    "            \n",
    "    #Convert to tensor (better to use lowercase \"tensor\" not \"Tensor\" since Tensor automatically assign the dtype to float32)\n",
    "    xs=torch.tensor(xs)\n",
    "    ys=torch.tensor(ys)    \n",
    "    num = xs.nelement() #Number of element in the tensor\n",
    "    \n",
    "    # randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "    # g = torch.Generator().manual_seed(2147483647)\n",
    "    W = torch.randn((27, 27), requires_grad=True) #requires_grad=True to make the weight can be updated by the optimizer\n",
    "    \n",
    "    #Model Training, gradient descent\n",
    "    for i in range(epoch):\n",
    "        #Forward pass\n",
    "        xenc = F.one_hot(xs, num_classes=27).float() \n",
    "        logits = xenc @ W \n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdims=True)\n",
    "        loss=-probs[torch.arange(num), ys].log().mean()\n",
    "        \n",
    "        #Backward pass\n",
    "        W.grad=None #Reset the gradient to zero\n",
    "        loss.backward() #Calculate the gradient, torch is like micrograd, it tracks the computation graph\n",
    "        \n",
    "        #Update weight\n",
    "        W.data += -learning_rate * W.grad\n",
    "        if i % 10 == 0:\n",
    "            print(f'Iter {i}, Loss {loss.item()}')\n",
    "            \n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 3.800018787384033\n",
      "Epoch 10, Loss 2.659454107284546\n",
      "Epoch 20, Loss 2.5612409114837646\n",
      "Epoch 30, Loss 2.5260512828826904\n",
      "Epoch 40, Loss 2.5074403285980225\n",
      "Epoch 50, Loss 2.4960408210754395\n",
      "Epoch 60, Loss 2.4883546829223633\n",
      "Epoch 70, Loss 2.482818841934204\n",
      "Epoch 80, Loss 2.4786510467529297\n",
      "Epoch 90, Loss 2.4754178524017334\n"
     ]
    }
   ],
   "source": [
    "#Model training\n",
    "W=NNBigram(100,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the neural net do the character prediction\n",
    "def predict_next_char(W):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "    for i in range(5):\n",
    "        out = []\n",
    "        ix = 0\n",
    "        while True:\n",
    "            xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "            logits = xenc @ W # predict log-counts\n",
    "            counts = logits.exp() # counts, equivalent to N\n",
    "            p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "            # ----------\n",
    "            #Generate the sample based on the probability in the row\n",
    "            ix = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "            out.append(itos[ix])\n",
    "            if ix == 0:\n",
    "                break\n",
    "        print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.\n",
      "ly.\n",
      "washja.\n",
      "jan.\n",
      "tlilytlo.\n"
     ]
    }
   ],
   "source": [
    "predict_next_char(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with Batch Norm (Dataset split + GPU Support)\n",
    "\n",
    "Predict next char based on 3 characters before, and with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size=3 #How many character used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    #Context size: berapa karakter sebelum yang dipake buat predict selanjutnya\n",
    "    X, Y= [], []\n",
    "    for w in words:\n",
    "        # print(w)\n",
    "        context=[0]*block_size #Padded context of 0 tokens -> [0]* 3 = [0,0,0] -> . . .\n",
    "        for ch in w+'.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            # print (''.join(itos[i] for i in context), '-->', itos[ix])\n",
    "            context=context[1:]+[ix] #rolling window of the context, remove char in first idx and add new char in last idx\n",
    "    #Convert to tensor\n",
    "    X= torch.tensor(X)\n",
    "    Y= torch.tensor(Y)\n",
    "    \n",
    "    print(X.shape, X.dtype, Y.shape, Y.dtype)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset split\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 3]) torch.int64 torch.Size([228146]) torch.int64\n",
      "torch.Size([182625, 3]) torch.int64 torch.Size([182625]) torch.int64\n",
      "torch.Size([22655, 3]) torch.int64 torch.Size([22655]) torch.int64\n",
      "torch.Size([22866, 3]) torch.int64 torch.Size([22866]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "n1= int(len(word)*0.8) #80% of the dataset\n",
    "n2= int(len(word)*0.9) #90% of the dataset\n",
    "\n",
    "X, Y= build_dataset(word)\n",
    "Xtr,Ytr= build_dataset(word[:n1]) #Train\n",
    "Xdev,Ydev= build_dataset(word[n1:n2]) #Validation -> 10% of the data (between 80% and 90% ; between Train and Test)\n",
    "Xte,Yte= build_dataset(word[n2:]) #Test -> 10% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move all to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "Xtr,Ytr,Xdev,Ydev,Xte,Yte = Xtr.to(device),Ytr.to(device),Xdev.to(device),Ydev.to(device),Xte.to(device),Yte.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "\n",
    "def trainBNest(max_steps = 200000, batch_size = 32,momentum=0.001, n_embd=10, n_hidden=200):\n",
    "    \n",
    "    vocab_size = len(itos)\n",
    "    C  = torch.randn((vocab_size, n_embd))\n",
    "    W1 = torch.randn((n_embd * block_size, n_hidden))*(5/3)/((n_embd * block_size)**0.5) #kaiming he normal init configuration\n",
    "    b1 = torch.randn(n_hidden)*0.01\n",
    "    W2 = torch.randn((n_hidden, vocab_size))*0.01\n",
    "    b2 = torch.randn(vocab_size)*0 \n",
    "\n",
    "    #BN parameters (Gain γ & Bias β) -> Scale and Shift\n",
    "    bngain=torch.ones((1,n_hidden))\n",
    "    bnbias=torch.zeros((1,n_hidden))\n",
    "    #Adding variable to estimate the mean and std (mean=0, std=1)\n",
    "    bnmean_running=torch.zeros((1,n_hidden))\n",
    "    bnstd_running=torch.ones((1,n_hidden))\n",
    "    \n",
    "    C,W1,b1,W2,b2 = C.to(device), W1.to(device), b1.to(device), W2.to(device), b2.to(device)\n",
    "    bnbias,bngain= bnbias.to(device), bngain.to(device)\n",
    "    bnmean_running,bnstd_running= bnmean_running.to(device), bnstd_running.to(device)\n",
    "    \n",
    "    parameters = [C, W1, b1, W2, b2,bngain,bnbias]\n",
    "    print('Num_params= ',sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        #Mini batch\n",
    "        ix=torch.randint(0,Xtr.shape[0],(batch_size,))\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "        Xb, Yb = Xb.to(device), Yb.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        emb = C[Xb]\n",
    "        embcat=emb.view(emb.shape[0],-1) \n",
    "        hpreact = embcat @ W1 +b1 #b1 is useless anyway since will get subtracted in BN process\n",
    "        \n",
    "        #Batch Normalization=gain*(mean/std)+bias\n",
    "        bnmeani=hpreact.mean(dim=0,keepdim=True) #current batch mean\n",
    "        bnstdi=hpreact.std(dim=0,keepdim=True) #current batch std\n",
    "    \n",
    "        hpreact=bngain*((hpreact-bnmeani)/(bnstdi))+bnbias\n",
    "        \n",
    "        #Updating the running mean and std seperately to the NN training\n",
    "        with torch.no_grad(): #The operation below is not used for gradient calculation\n",
    "            #Updating by moving average\n",
    "            bnmean_running=(1-momentum)*bnmean_running+momentum*bnmeani\n",
    "            bnstd_running=(1-momentum)*bnstd_running+momentum*bnstdi\n",
    "        \n",
    "        h = torch.tanh(hpreact)  \n",
    "        logits = h @ W2 + b2  \n",
    "        loss = F.cross_entropy(logits, Yb) \n",
    "        \n",
    "        #Backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None            \n",
    "        loss.backward()\n",
    "        \n",
    "        #Update parameters\n",
    "        lr = 0.1 if i < 100000 else 0.01\n",
    "        for p in parameters:\n",
    "            p.data -= lr*p.grad\n",
    "        \n",
    "        #Track stats\n",
    "        if i % 10000 == 0:\n",
    "            print(f'Step {i}, Loss {loss.item()}')\n",
    "        lossi.append(loss.log10().item())\n",
    "        \n",
    "    return parameters, lossi, bnmean_running, bnstd_running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_params=  12297\n",
      "Step 0, Loss 3.273175001144409\n",
      "Step 10000, Loss 2.600304126739502\n",
      "Step 20000, Loss 2.262950897216797\n",
      "Step 30000, Loss 2.483833074569702\n",
      "Step 40000, Loss 1.9275245666503906\n",
      "Step 50000, Loss 2.5291364192962646\n",
      "Step 60000, Loss 2.4137370586395264\n",
      "Step 70000, Loss 1.85837721824646\n",
      "Step 80000, Loss 2.5302340984344482\n",
      "Step 90000, Loss 2.2093753814697266\n",
      "Step 100000, Loss 2.297924757003784\n",
      "Step 110000, Loss 1.9407331943511963\n",
      "Step 120000, Loss 2.3918251991271973\n",
      "Step 130000, Loss 2.6181344985961914\n",
      "Step 140000, Loss 2.023646354675293\n",
      "Step 150000, Loss 2.1068196296691895\n",
      "Step 160000, Loss 1.764400839805603\n",
      "Step 170000, Loss 1.9678499698638916\n",
      "Step 180000, Loss 2.1252236366271973\n",
      "Step 190000, Loss 2.1495461463928223\n"
     ]
    }
   ],
   "source": [
    "parameters, lossi, bnmean_running, bnstd_running = trainBNest()\n",
    "C, W1, b1, W2, b2, bngain, bnbias = parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking to the function below or use '''with torch.no_grad()''': to disable gradient tracking\n",
    "def split_lossBNest(split, parameters):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  # parameters=parameters.to(device)\n",
    "  C,W1,b1,W2,b2,bngain,bnbias = parameters\n",
    "  C,W1,b1,W2,b2,bngain,bnbias = C.to(device),W1.to(device),b1.to(device),W2.to(device),b2.to(device),bngain.to(device),bnbias.to(device)\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact= embcat@W1 + b1\n",
    "  hpreact=bngain*((hpreact-bnmean_running)/(bnstd_running))+bnbias #Using fixed number from training set\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "  \n",
    "  return( h , (embcat@W1 + b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.069105625152588\n",
      "val 2.1114752292633057\n"
     ]
    }
   ],
   "source": [
    "split_lossBNest('train', parameters)\n",
    "h, hr=split_lossBNest('val', parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f0615543a0>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zay.\n",
      "makdiel.\n",
      "alyn.\n",
      "shyis.\n",
      "alee.\n",
      "emerf.\n",
      "tamen.\n",
      "stin.\n",
      "zika.\n",
      "juni.\n",
      "eliyah.\n",
      "bryg.\n",
      "aeriell.\n",
      "nie.\n",
      "keidenneik.\n",
      "chan.\n",
      "bailley.\n",
      "winne.\n",
      "prisja.\n",
      "torveysha.\n"
     ]
    }
   ],
   "source": [
    "# g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ... (block_size=3)\n",
    "    while True:\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "      embcat= emb.view(emb.shape[0], -1) # (1,block_size*d)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact=bngain*((hpreact-bnmean_running)/(bnstd_running))+bnbias\n",
    "      h = torch.tanh(hpreact)\n",
    "      logits = h @ W2 + b2\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      context = context[1:] + [ix] #Rolling window to update context for next character\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Pre-trained Transformer (GPT) Makemore\n",
    "The dataset is different from previous part\n",
    "\n",
    "Now the dataset used is [tinyshakespeare.txt,](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt) which can be changed in GPTMakemoretrain.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPTMakemoreModel\n",
    "from GPTMakemoreModel import GPTLanguageModel\n",
    "#Hyperparameters\n",
    "batch_size = 128\n",
    "block_size= 256 #Context size to predict next character (context=8 berarti predict karakter ke 9 berdasarkan 8 urutan sebelumnya)\n",
    "max_iters=10000\n",
    "eval_interval=250 #Do evaluation every eval_interval iterations\n",
    "learning_rate= 3e-4 #Self-attention ga terlalu bagus dengan learning rate yang tinggi\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Use GPU (NVIDA RTX for example) if available\n",
    "eval_iters=200\n",
    "n_embd = 384 #Embedding dimensionsize\n",
    "n_layer= 6 #Number of layers\n",
    "n_head=6 #Number of heads in multi-head attention\n",
    "dropout=0.2 #20% dropou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='tinyshakespeare.txt' # change to tinyshakespeare directory/file name\n",
    "with open(file_name,'r', encoding='utf-8') as f:\n",
    "    text=f.read()\n",
    "    \n",
    "#Vocab Ambil semua karakter unik dalam dataset\n",
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "# print(\"\".join(chars))\n",
    "# print(vocab_size)\n",
    "#Buat tabel untuk mapping karakter ke integer dan sebaliknya\n",
    "stoi={ch:i for i,ch in enumerate(chars)}\n",
    "itos={i:ch for i,ch in enumerate(chars)}\n",
    "#Encode (string->char to int)\n",
    "encode=lambda s: [stoi[ch] for ch in s]\n",
    "#Decode (int->char to string)\n",
    "decode=lambda l: \"\".join([itos[i] for i in l])\n",
    "\n",
    "#Train-Val split\n",
    "#Misahin data menjadi train set dan validation set, supaya model bisa belajar dan diuji, kemudian kita bisa cek ga ada overfitting, ga nginget dataset doang\n",
    "data=torch.tensor(encode(text), dtype=torch.long)\n",
    "n= int(0.9*len(data))\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]\n",
    "\n",
    "#Data loader\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data # milih split train atau val\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # generate random index positions, generate angka random 0 sampai len(data) - block_size sebanyak batch_sizenya, buat offset di training set\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # index ke i sampai i+block_size, ini inputnya, i itu angka yg ada di array ix\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]) # targetnya adalah x yang di offset 1\n",
    "    #torch.stack itu buat numpuk tensor-tensor 1D terus di tumpuk semua (stack them up at rows)\n",
    "    x, y = x.to(device), y.to(device) # jika ada GPU kalkulasinya bakal kerja di GPU, jadi dipindah ke GPU\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() #Kasih tau pytorch buat ga nyimpen gradient dari fungsi ini, karena ini buat evaluasi doang dan supaya lebih efisien\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval() # set model ke evaluation mode, karena jika layer layer tertentu bisa punya kelakuan beda saat inference(eval) dan training, contoh kek batchnorm\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # set model ke training mode\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTLanguageModel(vocab_size)\n",
    "m = model.to(device) # jika ada GPU kalkulasinya bakal kerja di GPU, jadi dipindah ke GPU\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# save the model\n",
    "model_name='model.pth'#Change to desired name\n",
    "torch.save(model.state_dict(), model_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample from GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='modelTinyShakeSpeare.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model_load=GPTLanguageModel(vocab_size)\n",
    "model_load.load_state_dict(torch.load(model_name))\n",
    "m=model_load.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device) #Start index\n",
    "#  [0] itu First dimension/firstbatch for predicition -> m.generate(context, max_new_tokens=500)[0].tolist()\n",
    "print(decode(m.generate(context, max_new_tokens=5000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
